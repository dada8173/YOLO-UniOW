"""
ç°¡åŒ–ç‰ˆæœ¬çš„æ–‡æœ¬ç‰¹å¾µæå–è…³æœ¬ - ç‚º GroZi-120 OWOD ç”Ÿæˆæ‰€æœ‰ä»»å‹™çš„åµŒå…¥
"""
import sys
import os
from pathlib import Path
import numpy as np
import torch

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from mmengine.config import Config
from mmengine.runner import Runner

def extract_grozi120_feats():
    """ç‚º GroZi-120 çš„æ‰€æœ‰ 4 å€‹ä»»å‹™ç”Ÿæˆæ–‡æœ¬åµŒå…¥"""
    
    # ç¢ºä¿åœ¨é …ç›®æ ¹ç›®éŒ„
    project_root = Path(__file__).parent.parent
    os.chdir(project_root)
    
    config_file = project_root / 'configs/pretrain/yolo_uniow_s_lora_bn_5e-4_100e_8gpus_obj365v1_goldg_train_lvis_minival.py'
    ckpt_file = project_root / 'pretrained/yolo_uniow_s_lora_bn_5e-4_100e_8gpus_obj365v1_goldg_train_lvis_minival.pth'
    save_path = project_root / 'embeddings/uniow-s'
    save_path.mkdir(parents=True, exist_ok=True)
    
    dataset_name = 'GroZi120OWOD'
    
    print("=" * 80)
    print(f"ğŸ“Š ç”Ÿæˆ {dataset_name} æ–‡æœ¬ç‰¹å¾µåµŒå…¥")
    print("=" * 80)
    
    try:
        # è¼‰å…¥é…ç½®å’Œæ¨¡å‹
        print(f"\n1ï¸âƒ£ è¼‰å…¥é…ç½®: {config_file.name}")
        cfg = Config.fromfile(str(config_file))
        cfg.work_dir = str(project_root / 'work_dirs/extract_feats')
        
        print(f"2ï¸âƒ£ åˆå§‹åŒ–é‹è¡Œå™¨...")
        runner = Runner.from_cfg(cfg)
        runner.call_hook("before_run")
        
        print(f"3ï¸âƒ£ è¼‰å…¥æª¢æŸ¥é»: {ckpt_file.name}")
        runner.load_checkpoint(str(ckpt_file), map_location='cpu')
        
        print(f"4ï¸âƒ£ æ¨¡å‹è½‰ç§»åˆ° GPU...")
        model = runner.model
        if torch.cuda.is_available():
            model = model.cuda()
            print("   âœ… ä½¿ç”¨ GPU")
        else:
            print("   âš ï¸  GPU ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU")
        model.eval()
        
        # ç‚ºæ¯å€‹ä»»å‹™æå–ç‰¹å¾µ
        print(f"\n5ï¸âƒ£ æå–æ–‡æœ¬ç‰¹å¾µ:")
        for task_id in range(1, 5):
            print(f"\n   Task {task_id}:")
            
            # è®€å–è©²ä»»å‹™çš„å·²çŸ¥é¡åˆ¥
            class_text_path = project_root / f'data/OWOD/ImageSets/{dataset_name}/t{task_id}_known.txt'
            print(f"     è®€å–é¡åˆ¥æ–‡ä»¶: {class_text_path.name}")
            
            with open(str(class_text_path), 'r', encoding='utf-8') as f:
                class_names = [line.strip() for line in f.readlines()]
            
            print(f"     å·²çŸ¥é¡åˆ¥æ•¸: {len(class_names)}")
            
            # æå–ç‰¹å¾µ
            with torch.no_grad():
                text_feats = model.backbone.forward_text([class_names]).squeeze(0).detach().cpu()
            
            # ä¿å­˜
            save_file = save_path / f'{dataset_name.lower()}_t{task_id}.npy'
            np.save(str(save_file), text_feats.numpy())
            print(f"     âœ… ä¿å­˜åˆ°: {save_file}")
            print(f"     ç‰¹å¾µå½¢ç‹€: {text_feats.shape}")
        
        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰€æœ‰ä»»å‹™çš„æ–‡æœ¬ç‰¹å¾µå·²ç”Ÿæˆï¼")
        print("=" * 80)
        print(f"\nç”Ÿæˆçš„æ–‡ä»¶:")
        for task_id in range(1, 5):
            save_file = save_path / f'{dataset_name.lower()}_t{task_id}.npy'
            if save_file.exists():
                size = save_file.stat().st_size / (1024*1024)  # è½‰æ›ç‚º MB
                print(f"  âœ… {save_file.name:40s} ({size:.2f} MB)")
        
    except Exception as e:
        print(f"\nâŒ éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == '__main__':
    os.chdir(Path(__file__).parent.parent.parent)  # åˆ‡æ›åˆ°é …ç›®æ ¹ç›®éŒ„
    success = extract_grozi120_feats()
    sys.exit(0 if success else 1)
